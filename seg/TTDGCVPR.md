# å¤ç°åŸºæœ¬ä¿¡æ¯
github:
https://github.com/Yore0/TTDG-MGM  
  
Paper:
https://www.alphaxiv.org/abs/2503.13012 
  
æ•°æ®é›†ï¼š
https://drive.google.com/drive/folders/1axgu3-65un-wA_1OH-tQIUIEHEDrnS_-  
  
Fundus(çœ¼åº•)çš„æ•°æ®é›†å’ŒPolyp(æ¯è‚‰)çš„æ•°æ®é›†éƒ½åœ¨é‡Œé¢  
  
Fundusï¼šRIM-ONE,REFUGE,ORIGA,REFUGE-TEST,Drishti-GS  
  
Polypï¼šBKAI-IGH-NEOPolyp,CVC-ClinicDB,ETIS,Kvasir  
  


# 1.ç¯å¢ƒå®‰è£…Install
```
conda create -n ttdg python=3.7 -y
conda activate ttdg
pip install -r requirements.txt
```
# 2.dataä»‹ç»ä¸ä¸Šä¼ 
## multi-source generalization
ç”¨åˆ°çš„æ•°æ®é›†ï¼šFundusçš„æ•°æ®é›†ã€‚REFUGE, ORIGA,  Drishti_GS,RIM_ONE_r3      æ²¡è¯´æ¨¡æ€ï¼Œæ˜¯2Dçš„ï¼Œä¸€å…±1.01GB  
è®­ç»ƒé›†ï¼šREFUGE(å‡ä¸ºpng),       ORIGA(å›¾åƒjpg,æ ‡ç­¾png,77M),     Drishti_GS(å›¾åƒæ ‡ç­¾å‡ä¸ºpngï¼Œ63M)ï¼Œ  
| è®­ç»ƒé›† | æ ¼å¼ | å†…å­˜ |
| ---- | ---- | ---- |
| REFUGE | å‡ä¸ºpng | 820M |
| ORIGA | å›¾åƒjpg,æ ‡ç­¾png | 77 |
| Drishti_GS | å›¾åƒæ ‡ç­¾å‡ä¸ºpng | 63 |  

æµ‹è¯•é›†ï¼šRIM_ONE_r3ï¼Œæ ‡ç­¾å’Œimageä¸º.pngï¼Œå†…å­˜120M


## single-source generalizationâ€‹
ç”¨åˆ°çš„æ•°æ®é›†ï¼šPolypçš„æ•°æ®é›†ã€‚BKAI-IGH-NEOPolyp,CVC-ClinicDB      æ²¡è¯´æ¨¡æ€ï¼Œæ˜¯2Dçš„ï¼Œä¸€å…±367M  
æµ‹è¯•é›†ï¼šBKAI-IGH-NEOPolyp          imageå’Œlabelä¸ºjpeg    302M  
è®­ç»ƒé›†ï¼šCVC-ClinicDB                    å‡ä¸ºpng         65M     

# 3.å¤ç°æ­¥éª¤å®ç°
## 3.1 COCO æ ¼å¼jsonæ„å»º
```
import os
import cv2
import json
import numpy as np
from glob import glob

def masks_to_coco(image_dir, mask_dir, output_json, min_area=200):
    """
    å°†å¤šç±»åˆ«ï¼ˆOD=128, OC=255ï¼‰æ©ç è½¬æ¢ä¸º COCO æ ¼å¼
    - ä½¿ç”¨å½¢æ€å­¦é—­è¿ç®—å¹³æ»‘è½®å»“
    - å¿½ç•¥é¢ç§¯è¿‡å°çš„ä¼ªå½±åŒºåŸŸ
    - æ¯å¼ å›¾åªä¿ç•™ä¸€ä¸ª OD å’Œä¸€ä¸ª OCï¼ˆå–æœ€å¤§é¢ç§¯ï¼‰
    """
    images = []
    annotations = []
    categories = [
        {"id": 1, "name": "OpticDisc", "supercategory": "fundus"},
        {"id": 2, "name": "OpticCup", "supercategory": "fundus"}
    ]

    ann_id = 1
    img_id = 1

    image_files = sorted(glob(os.path.join(image_dir, "*.png")) + 
                         glob(os.path.join(image_dir, "*.jpg")))

    for file in image_files:
        filename = os.path.basename(file)
        mask_file = os.path.join(mask_dir, filename.replace(".jpg", ".png"))
        if not os.path.exists(mask_file):
            print(f"[WARN] æ‰¾ä¸åˆ°å¯¹åº”æ©ç : {mask_file}")
            continue

        img = cv2.imread(file)
        if img is None:
            print(f"[WARN] æ— æ³•è¯»å–å›¾åƒ: {file}")
            continue

        h, w = img.shape[:2]
        images.append({
            "id": img_id,
            "file_name": filename,
            "width": w,
            "height": h
        })

        # è¯»å–æ©ç 
        mask = cv2.imread(mask_file, cv2.IMREAD_GRAYSCALE)
        if mask is None:
            print(f"[WARN] æ— æ³•è¯»å–æ©ç : {mask_file}")
            continue

        # å½¢æ€å­¦é—­è¿ç®—æ ¸
        kernel = np.ones((5, 5), np.uint8)

        for cat_id, pixel_val in [(1, 128), (2, 255)]:
            binary_mask = (mask == pixel_val).astype('uint8')

            # ğŸ”¹ é—­è¿ç®— (å»å°å­”ã€è¿é€šå°å—)
            binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_CLOSE, kernel)

            # è¿é€šåŒºåŸŸåˆ†æ
            num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(binary_mask, connectivity=8)

            if num_labels <= 1:
                continue  # æ— å‰æ™¯

            # æ‰¾æœ€å¤§åŒºåŸŸï¼ˆä¸»ç›®æ ‡ï¼‰
            areas = stats[1:, cv2.CC_STAT_AREA]
            largest_idx = np.argmax(areas) + 1  # +1 å› ä¸º stats[0] æ˜¯èƒŒæ™¯
            largest_mask = (labels == largest_idx).astype('uint8')

            # æå–è½®å»“
            contours, _ = cv2.findContours(largest_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            if len(contours) == 0:
                continue

            contour = max(contours, key=cv2.contourArea)
            area = cv2.contourArea(contour)
            if area < min_area:
                continue  # å¿½ç•¥å¤ªå°çš„åŒºåŸŸ

            x, y, bw, bh = cv2.boundingRect(contour)
            segmentation = contour.flatten().tolist()

            annotations.append({
                "id": ann_id,
                "image_id": img_id,
                "category_id": cat_id,
                "segmentation": [segmentation],
                "bbox": [x, y, bw, bh],
                "area": float(area),
                "iscrowd": 0
            })
            ann_id += 1

        img_id += 1

    # === å†™å‡º COCO JSON ===
    coco_dict = {
        "images": images,
        "annotations": annotations,
        "categories": categories
    }

    os.makedirs(os.path.dirname(output_json), exist_ok=True)
    with open(output_json, "w") as f:
        json.dump(coco_dict, f, indent=4)

    print(f"[INFO] âœ… å·²ç”Ÿæˆ: {output_json}, å›¾ç‰‡æ•°={len(images)}, æ ‡æ³¨æ•°={len(annotations)}")


if __name__ == "__main__":
    root = "/root/autodl-tmp/datasets/Fundus"

    datasets = [
        "Drishti_GS/test",
        "Drishti_GS/train",
        "ORIGA/test",
        "ORIGA/train",
        "REFUGE/test",
        "REFUGE/train",
        "REFUGE_Valid",
        "RIM_ONE_r3/test",
        "RIM_ONE_r3/train"
    ]

    for dataset in datasets:
        img_dir = os.path.join(root, dataset, "image")
        mask_dir = os.path.join(root, dataset, "mask")
        output_json = os.path.join(root, dataset.replace("/", "_") + ".json")
        masks_to_coco(img_dir, mask_dir, output_json)
```
## æŠ¥é”™
### 3.1.1
```
é—®é¢˜ï¼špolypæ ‡æ³¨æ•°å¤§äºå›¾ç‰‡æ•°ï¼Œä½†ä¸€ä¸ªå›¾ç‰‡åº”è¯¥åªæœ‰ä¸€ä¸ªæ ‡æ³¨
åŸå› ï¼š(ttdg) root@autodl-container-0fc04ca4ba-2313fd84:~/autodl-tmp# 
python /root/autodl-tmp/plpolypdajs.py unique pixel values: 
[ 0 1 2 3 4 5 6 7 8 248 249 250 251 252 253 254 255] connected components (excluding bg): 1 findContours returned: 1
æ©ç ä¸æ˜¯çº¯é»‘ç™½äºŒå€¼å›¾ï¼Œè€Œæ˜¯è¢«ä¿å­˜æˆäº†ç°åº¦æ¸å˜æˆ–è€…æœ‰è½»å¾®å‹ç¼©è¯¯å·®çš„å›¾åƒï¼ˆæ¯”å¦‚ JPEG ä¿å­˜è¿‡ã€æˆ–è€… PNG å‹ç¼©å‡ºäº†ä¸€å †ä¼ªåƒï¼‰ã€‚

è§£å†³æ–¹æ³•ï¼šå¼ºè¡ŒäºŒå€¼åŒ–
mask = cv2.imread(mask_file, cv2.IMREAD_GRAYSCALE)
mask = np.where(mask > 128, 255, 0).astype(np.uint8)
```
### 3.1.2
```
é—®é¢˜:
fundusçš„æ ‡æ³¨æ•°é‡åº”è¯¥æ˜¯å›¾ç‰‡æ•°é‡ä¸¤å€ï¼Œä½†æ˜¯å¤šå¾ˆå¤š

åŸå› ï¼šæŠŠå¾ˆå°çš„è¿é€šåŒºåŸŸä¹Ÿæ ‡è¿›å»äº†

è§£å†³æ–¹æ³•ï¼š
å¿½ç•¥å°ç¢ç‰‡
num_labels, labels = cv2.connectedComponents(binm)
area_thresh = binm.size * 0.001  # å°äº0.1%åƒç´ é¢ç§¯çš„å¿½ç•¥
counts = 0
for i in range(1, num_labels):
    if np.sum(labels == i) >= area_thresh:
        counts += 1

```
```
é—®é¢˜ï¼š
Assertion `t >= 0 && t < n_classes` failed
æ ‡ç­¾å’Œæ¨¡å‹è¾“å‡ºç±»åˆ«æ•°ä¸åŒ¹é…

è§£å†³æ–¹æ³•ï¼š
éªŒè¯é›†è®¾ç½®é”™è¯¯ï¼Œæ”¹ä¸€ä¸‹éªŒè¯é›†
```
```
é—®é¢˜ï¼š
ValueError: Does not validate against any of the Union subtypes
Subtypes: [<class 'NoneType'>, <class 'lightning.pytorch.core.module.LightningModule'>]
Errors:
  - Expected a <class 'NoneType'>
  - 'init_args'
Given value type: <class 'jsonargparse._namespace.Namespace'>
Given value: Namespace(class_path='chest_xray.pl_modules.DomainConditionedCXRLitModule', init_args=Namespace(...))

è§£å†³æ–¹æ³•ï¼šè¿™æ˜¯ç”¨ctrl Cä¸­æ–­è®­ç»ƒå¯¼è‡´æƒé‡ä¸å®Œæ•´å¯¼è‡´çš„ï¼Œå®Œæ•´è®­ç»ƒå°±å¯ä»¥
```
```
é—®é¢˜ï¼š
KeyError: np.int64(1)
wandb.log({"conf_mat": confusion_matrix(preds=val_domain_preds, y_true=val_domain_labels, class_names=self.cls_names)})

è§£å†³æ–¹æ³•ï¼š
ç±»åˆ«æ˜ å°„é‚£é‡Œä¿®æ”¹äº†ä¸€ä¸‹å¹¶ä¸”å¦‚æœè®­ç»ƒæ—¶åªæœ‰ä¸€ä¸ªåŸŸå°±ä¸ç”»æ··æ·†çŸ©é˜µ
```
## 3.2  training
python train_net.py \
      --num-gpus 1 \
      --config configs/seg_res50fpn_source.yaml\
      OUTPUT_DIR output/<name>
## æŠ¥é”™
### 3.2.1
```
é—®é¢˜:
RuntimeError(CUDA_MISMATCH_MESSAGE.format(cuda_str_version, torch.version.cuda))
 RuntimeError: The detected CUDA version (12.1) mismatches the version that was used to compile PyTorch (11.3). Please make sure to use the same CUDA versions. 
[end of output] note: This error originates from a subprocess, and is likely not a problem with pip.
ï¼ƒä½ çš„ä»£ç  README æŒ‡å®š Detectron2 0.5

ä½ æœåŠ¡å™¨ä¸Š PyTorch æ˜¯ 1.10 + CUDA 11.3

ä½ æœåŠ¡å™¨çš„ GPU æ˜¯ RTX 3080 Tiï¼ˆsm_86ï¼‰

ä½ ä¹‹å‰å°è¯•å®‰è£… Detectron2 0.5 éƒ½å› ä¸ºç½‘ç»œé—®é¢˜æˆ–è€… CUDA ç‰ˆæœ¬ä¸åŒ¹é…å¤±è´¥

è§£å†³æ–¹æ³•ï¼š
ä½¿ç”¨å’Œpytorchå’ŒcudaåŒ¹é…çš„detectron2ç‰ˆæœ¬ï¼Œç„¶åæ”¹ç”¨0.5ç‰ˆæœ¬çš„è¯­å¥
pip install detectron2==0.6 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu113/torch1.10/index.html

# adapteacher/modeling/roi_heads/fast_rcnn.py
# å°†ï¼š
# from detectron2.modeling.roi_heads.fast_rcnn import FastRCNNOutputs
# æ”¹ä¸ºï¼š
from detectron2.modeling.roi_heads.fast_rcnn import FastRCNNOutputLayers
```


### 3.2.2
```
é—®é¢˜ï¼šæ˜¾å­˜ä¸è¶³
è§£å†³æ–¹æ³•ï¼šæ”¹patch å¤§å°
```
## 3.3 finetune and evalute
```
python train_net.py --eval-only --config configs/test_segment.yaml \
                MODEL.WEIGHTS <your weight>.pth
```
## æŠ¥é”™
### 3.3.1
æ•ˆæœå·®å¾ˆå¤š  
è§£å†³æ–¹æ³•ï¼šæŠŠå­¦ä¹ ç‡æ ¹æ®GPUæ•°é‡æ”¹ä¸€ä¸‹ï¼Œpatchçš„å¤§å°æ”¹æˆåŸæ–‡ç”¨çš„å…¶ä»–æ–‡çŒ®ä¸­çš„å¤§å°
## 3.4 Results
æŒ‡æ ‡ä¸ºDice score (DSC, %)ï¼Œ Emax(ä¸€ä¸ªè®ºæ–‡æå‡ºçš„)ï¼Œ SÎ±(ä¸€ä¸ªè®ºæ–‡æå‡ºçš„)ï¼Œè¶Šé«˜è¶Šå¥½  
![](../pictures/68614a73-15ba-400c-bd0c-9896b29dceeb.jpg)  
![](../pictures/601d4f0e-7c8e-4ef0-9450-0c296887b0bb.png)


